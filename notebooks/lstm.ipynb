{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2db941a-2b87-4a05-b325-c4a72fb7b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Any, Mapping, List, Tuple, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from loguru import logger\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.init import constant_, kaiming_normal_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn.utils.rnn import pack_sequence, unpack_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38609988-6e1b-4d98-a0db-356a34bfd81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/Users/artemvopilov/Programming/yandex_cup_2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd9a94d-fbff-4211-8b4f-015684ad331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = f\"{BASE_DIR}/data\"\n",
    "\n",
    "TRAIN_DF_PATH = f\"{DATA_DIR}/train.csv\"\n",
    "TEST_DF_PATH = f\"{DATA_DIR}/test.csv\"\n",
    "\n",
    "NORMED_EMBEDDINGS_DIR = f\"{BASE_DIR}/normed_embeddings\"\n",
    "PCA_EMBEDDINGS_DIR = f\"{BASE_DIR}/pca_embeddings\"\n",
    "VAE_EMBEDDINGS_DIR = f\"{BASE_DIR}/vae_embeddings\"\n",
    "NORMED_LSTM_EMBEDDINGS_DIR = f\"{BASE_DIR}/normed_lstm_embeddings\"\n",
    "VAE_LSTM_EMBEDDINGS_DIR = f\"{BASE_DIR}/vae_lstm_embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2858b17-a1e6-400b-b9d4-95d71b1ec0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cpu\"\n",
    "\n",
    "TAGS_N = 256\n",
    "\n",
    "INPUT_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = TAGS_N\n",
    "\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e8262d-2e63-4fa2-83f3-e90eedbf611d",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4828974f-1341-42c2-a788-a4077853d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_DF_PATH)\n",
    "test_df = pd.read_csv(TEST_DF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65311050-ae7f-455b-9c19-56872c707cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef055d9d0d814f7e9230f2d1c93a0804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "track_id_to_embeddings = {}\n",
    "for fn in tqdm(os.listdir(VAE_EMBEDDINGS_DIR)):\n",
    "    fp = f\"{VAE_EMBEDDINGS_DIR}/{fn}\"\n",
    "\n",
    "    track_id = fn.split('.')[0]\n",
    "    embeddings = np.load(fp).astype(np.float32)\n",
    "    track_id_to_embeddings[track_id] = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8def69a2-f7b9-40b2-8a47-e56d171ff179",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "869d3554-064f-4128-bbf6-dc4150fdda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, track_id_to_embeddings: Dict[str, np.ndarray[np.float64]], tags_n: int, is_testing=False):\n",
    "        self._df = df\n",
    "        self._track_id_to_embeddings = track_id_to_embeddings\n",
    "        self._tags_n = tags_n\n",
    "        self._is_testing = is_testing\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[str, np.ndarray[np.float64], List[np.ndarray[np.int64]]]:\n",
    "        row = self._df.iloc[index]\n",
    "        track_id = row[\"track\"]\n",
    "        embeddings = self._track_id_to_embeddings[str(track_id)]\n",
    "        if self._is_testing:\n",
    "            return track_id, embeddings, np.array([])\n",
    "        tags = [int(x) for x in row[\"tags\"].split(',')]\n",
    "        target = np.zeros(self._tags_n)\n",
    "        target[tags] = 1\n",
    "        return track_id, embeddings, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a19ff4e5-46ea-4a25-99dc-0bf09492af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(b):\n",
    "    track_ids = torch.from_numpy(np.vstack([x[0] for x in b]))\n",
    "    embeddings = [torch.from_numpy(x[1]) for x in b]\n",
    "    targets = torch.from_numpy(np.vstack([x[2] for x in b]))\n",
    "    return track_ids, embeddings, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebe2258-1b70-4fad-8998-de418c3e3dae",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6d37416-0c70-4689-aaa9-25bf856b6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.apply(self._init_layer)\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        embeddings = pack_sequence(embeddings, enforce_sorted=False)\n",
    "        cell_states, (final_hidden_state, final_cell_state) = self.lstm(embeddings)\n",
    "        first_layer_hidden_state = final_hidden_state[0, :, :]\n",
    "        return self.fc(first_layer_hidden_state), unpack_sequence(cell_states)\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.apply(self._init_layer)\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_layer(layer: nn.Module) -> None:\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            kaiming_normal_(layer.weight.data)\n",
    "            if layer.bias is not None:\n",
    "                constant_(layer.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664cc074-cacf-465d-89ea-17efab1f1ed9",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06bf6112-8da7-4711-bdcb-f0ffbd4246f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = None\n",
    "    alpha = 0.8\n",
    "    for iteration, data in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        _, embeddings, target = data\n",
    "        \n",
    "        embeddings = [x.to(DEVICE) for x in embeddings]\n",
    "        target = target.to(DEVICE)\n",
    "        \n",
    "        predictions, _ = model(embeddings)\n",
    "        \n",
    "        loss = criterion(predictions, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if running_loss is None:\n",
    "            running_loss = loss.item()\n",
    "        else:\n",
    "            running_loss = alpha * loss.item() + (1 - alpha) * loss.item()\n",
    "        if iteration % 100 == 0:\n",
    "            logger.info(\"{} batch {} loss {}\".format(datetime.now(), iteration + 1, running_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584367b0-bc2d-4144-8d25-e59f752e49fd",
   "metadata": {},
   "source": [
    "### Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8655338e-d0a1-432b-90c7-c7427bade20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    track_ids = []\n",
    "    predictions = []\n",
    "    cell_states = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            track_id, embeddings, _ = data\n",
    "            \n",
    "            embeddings =  [x.to(DEVICE) for x in embeddings]\n",
    "            \n",
    "            batch_predictions, batch_cell_states = model(embeddings)\n",
    "\n",
    "            track_ids.append(track_id.numpy())\n",
    "            predictions.append(batch_predictions.detach().cpu().numpy())\n",
    "            cell_states.append([cs.detach().cpu().numpy() for cs in batch_cell_states])\n",
    "    track_ids = np.vstack(track_ids).ravel()\n",
    "    predictions = np.vstack(predictions)\n",
    "    cell_states = list(chain.from_iterable(cell_states))\n",
    "    return track_ids, predictions, cell_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a5a141-ea98-4753-8632-43b130031501",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e11ee9e2-aa1a-46fa-95bf-09c40bc7a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LSTMDataset(train_df, track_id_to_embeddings, TAGS_N, False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2c438e2-e1fe-42e9-a39f-7378cb9da57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5685878d2d4d2092fbee5d0938f35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-12 10:49:18.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 10:49:18.657900 batch 1 loss 21.46189323812723\u001b[0m\n",
      "\u001b[32m2023-11-12 10:49:57.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 10:49:57.720021 batch 101 loss 18.576463600620627\u001b[0m\n",
      "\u001b[32m2023-11-12 10:50:39.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 10:50:39.105831 batch 201 loss 17.581225898116827\u001b[0m\n",
      "\u001b[32m2023-11-12 10:51:22.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 10:51:22.394743 batch 301 loss 16.930438693612814\u001b[0m\n",
      "\u001b[32m2023-11-12 10:52:03.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 10:52:03.372186 batch 401 loss 16.94636393431574\u001b[0m\n",
      "\u001b[32m2023-11-12 10:52:43.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 10:52:43.525861 batch 501 loss 16.147415263578296\u001b[0m\n",
      "\u001b[32m2023-11-12 10:53:26.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 10:53:26.611269 batch 601 loss 14.61594226770103\u001b[0m\n",
      "\u001b[32m2023-11-12 10:54:06.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 10:54:06.681739 batch 701 loss 17.365219809114933\u001b[0m\n",
      "\u001b[32m2023-11-12 10:54:45.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 10:54:45.338094 batch 1 loss 17.3214956484735\u001b[0m\n",
      "\u001b[32m2023-11-12 10:55:21.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 10:55:21.121668 batch 101 loss 14.808781633153558\u001b[0m\n",
      "\u001b[32m2023-11-12 10:55:56.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 10:55:56.357086 batch 201 loss 15.925026854500175\u001b[0m\n",
      "\u001b[32m2023-11-12 10:56:33.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 10:56:33.306980 batch 301 loss 16.155963096767664\u001b[0m\n",
      "\u001b[32m2023-11-12 10:57:08.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 10:57:08.464012 batch 401 loss 14.53885911218822\u001b[0m\n",
      "\u001b[32m2023-11-12 10:57:41.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 10:57:41.574747 batch 501 loss 16.498435446992517\u001b[0m\n",
      "\u001b[32m2023-11-12 10:58:16.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 10:58:16.707441 batch 601 loss 16.266007505357265\u001b[0m\n",
      "\u001b[32m2023-11-12 10:58:53.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 10:58:53.633686 batch 701 loss 17.025188634172082\u001b[0m\n",
      "\u001b[32m2023-11-12 10:59:27.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 10:59:27.078754 batch 1 loss 15.149369714781642\u001b[0m\n",
      "\u001b[32m2023-11-12 11:00:03.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:00:03.094768 batch 101 loss 17.287217432633042\u001b[0m\n",
      "\u001b[32m2023-11-12 11:00:39.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:00:39.326947 batch 201 loss 16.936614379286766\u001b[0m\n",
      "\u001b[32m2023-11-12 11:01:15.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:01:15.907691 batch 301 loss 16.293193554505706\u001b[0m\n",
      "\u001b[32m2023-11-12 11:01:49.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:01:49.686467 batch 401 loss 17.258580956608057\u001b[0m\n",
      "\u001b[32m2023-11-12 11:02:26.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:02:26.348352 batch 501 loss 14.773848356679082\u001b[0m\n",
      "\u001b[32m2023-11-12 11:03:03.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:03:03.916269 batch 601 loss 18.015034094452858\u001b[0m\n",
      "\u001b[32m2023-11-12 11:03:37.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:03:37.640497 batch 701 loss 17.159694083034992\u001b[0m\n",
      "\u001b[32m2023-11-12 11:04:13.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:04:13.808162 batch 1 loss 14.109189869835973\u001b[0m\n",
      "\u001b[32m2023-11-12 11:04:51.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:04:51.244765 batch 101 loss 14.585603651590645\u001b[0m\n",
      "\u001b[32m2023-11-12 11:05:26.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:05:26.384261 batch 201 loss 17.41415856592357\u001b[0m\n",
      "\u001b[32m2023-11-12 11:06:03.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:06:03.105513 batch 301 loss 14.948803000152111\u001b[0m\n",
      "\u001b[32m2023-11-12 11:06:37.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:06:37.707802 batch 401 loss 17.086198922246695\u001b[0m\n",
      "\u001b[32m2023-11-12 11:07:12.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:07:12.533571 batch 501 loss 12.617185439914465\u001b[0m\n",
      "\u001b[32m2023-11-12 11:07:53.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:07:53.082625 batch 601 loss 15.798823291435838\u001b[0m\n",
      "\u001b[32m2023-11-12 11:08:29.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:08:29.708066 batch 701 loss 14.01598456595093\u001b[0m\n",
      "\u001b[32m2023-11-12 11:09:09.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:09:09.278694 batch 1 loss 16.55054596439004\u001b[0m\n",
      "\u001b[32m2023-11-12 11:09:49.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:09:49.161503 batch 101 loss 14.51298150792718\u001b[0m\n",
      "\u001b[32m2023-11-12 11:10:24.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:10:24.460706 batch 201 loss 15.325212886556983\u001b[0m\n",
      "\u001b[32m2023-11-12 11:11:03.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:11:03.412811 batch 301 loss 14.93993734382093\u001b[0m\n",
      "\u001b[32m2023-11-12 11:11:39.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:11:39.888163 batch 401 loss 14.993155226111412\u001b[0m\n",
      "\u001b[32m2023-11-12 11:12:10.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:12:10.235959 batch 501 loss 15.596669102087617\u001b[0m\n",
      "\u001b[32m2023-11-12 11:12:41.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:12:41.061300 batch 601 loss 14.805416200309992\u001b[0m\n",
      "\u001b[32m2023-11-12 11:13:17.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:13:17.483808 batch 701 loss 15.22736445069313\u001b[0m\n",
      "\u001b[32m2023-11-12 11:13:55.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:13:55.102844 batch 1 loss 15.178332280367613\u001b[0m\n",
      "\u001b[32m2023-11-12 11:14:31.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:14:31.160049 batch 101 loss 15.161067795008421\u001b[0m\n",
      "\u001b[32m2023-11-12 11:15:04.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:15:04.841869 batch 201 loss 13.52508648764342\u001b[0m\n",
      "\u001b[32m2023-11-12 11:15:45.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:15:45.220670 batch 301 loss 14.77391367405653\u001b[0m\n",
      "\u001b[32m2023-11-12 11:16:30.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:16:30.843049 batch 401 loss 14.003672160208225\u001b[0m\n",
      "\u001b[32m2023-11-12 11:17:06.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:17:06.319975 batch 501 loss 13.896566392853856\u001b[0m\n",
      "\u001b[32m2023-11-12 11:17:45.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:17:45.555008 batch 601 loss 14.495229508727789\u001b[0m\n",
      "\u001b[32m2023-11-12 11:18:21.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:18:21.718552 batch 701 loss 15.546872597187757\u001b[0m\n",
      "\u001b[32m2023-11-12 11:19:04.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:19:04.938678 batch 1 loss 15.211019933223724\u001b[0m\n",
      "\u001b[32m2023-11-12 11:19:44.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:19:44.807865 batch 101 loss 12.99462678655982\u001b[0m\n",
      "\u001b[32m2023-11-12 11:20:24.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:20:24.079271 batch 201 loss 15.876235717907548\u001b[0m\n",
      "\u001b[32m2023-11-12 11:21:05.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:21:05.605661 batch 301 loss 13.07460278365761\u001b[0m\n",
      "\u001b[32m2023-11-12 11:21:44.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:21:44.371960 batch 401 loss 15.64032687805593\u001b[0m\n",
      "\u001b[32m2023-11-12 11:22:27.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:22:27.449374 batch 501 loss 15.193023968487978\u001b[0m\n",
      "\u001b[32m2023-11-12 11:23:05.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:23:05.569010 batch 601 loss 16.392093955539167\u001b[0m\n",
      "\u001b[32m2023-11-12 11:23:41.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:23:41.530252 batch 701 loss 14.176156324334443\u001b[0m\n",
      "\u001b[32m2023-11-12 11:24:19.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:24:19.014095 batch 1 loss 13.61744918487966\u001b[0m\n",
      "\u001b[32m2023-11-12 11:25:00.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:25:00.446621 batch 101 loss 13.32637132331729\u001b[0m\n",
      "\u001b[32m2023-11-12 11:25:37.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:25:37.511614 batch 201 loss 12.344364879652858\u001b[0m\n",
      "\u001b[32m2023-11-12 11:26:17.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:26:17.155309 batch 301 loss 14.107307478785515\u001b[0m\n",
      "\u001b[32m2023-11-12 11:26:55.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:26:55.968662 batch 401 loss 15.083217546343803\u001b[0m\n",
      "\u001b[32m2023-11-12 11:27:29.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:27:29.150066 batch 501 loss 15.131143506616354\u001b[0m\n",
      "\u001b[32m2023-11-12 11:28:08.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:28:08.766954 batch 601 loss 15.029085481539369\u001b[0m\n",
      "\u001b[32m2023-11-12 11:28:47.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:28:47.780221 batch 701 loss 13.884915372356772\u001b[0m\n",
      "\u001b[32m2023-11-12 11:29:24.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:29:24.867598 batch 1 loss 13.837577586062253\u001b[0m\n",
      "\u001b[32m2023-11-12 11:30:04.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:30:04.347799 batch 101 loss 15.964722961187363\u001b[0m\n",
      "\u001b[32m2023-11-12 11:30:43.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:30:43.167323 batch 201 loss 15.36829007230699\u001b[0m\n",
      "\u001b[32m2023-11-12 11:31:22.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:31:22.140748 batch 301 loss 12.398102684877813\u001b[0m\n",
      "\u001b[32m2023-11-12 11:31:59.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:31:59.624556 batch 401 loss 16.239842565730214\u001b[0m\n",
      "\u001b[32m2023-11-12 11:32:37.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:32:37.054109 batch 501 loss 15.385813776403666\u001b[0m\n",
      "\u001b[32m2023-11-12 11:33:12.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:33:12.214111 batch 601 loss 15.404163053259254\u001b[0m\n",
      "\u001b[32m2023-11-12 11:33:49.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:33:49.862716 batch 701 loss 15.521329468116164\u001b[0m\n",
      "\u001b[32m2023-11-12 11:34:25.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:34:25.911805 batch 1 loss 14.440916455350816\u001b[0m\n",
      "\u001b[32m2023-11-12 11:35:02.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:35:02.955712 batch 101 loss 14.85561396740377\u001b[0m\n",
      "\u001b[32m2023-11-12 11:35:41.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:35:41.813550 batch 201 loss 15.313649401068687\u001b[0m\n",
      "\u001b[32m2023-11-12 11:36:29.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:36:29.289311 batch 301 loss 14.648808320984244\u001b[0m\n",
      "\u001b[32m2023-11-12 11:37:06.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:37:06.464706 batch 401 loss 15.614195086993277\u001b[0m\n",
      "\u001b[32m2023-11-12 11:37:41.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:37:41.968652 batch 501 loss 14.76795303169638\u001b[0m\n",
      "\u001b[32m2023-11-12 11:38:18.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:38:18.256986 batch 601 loss 15.52695794776082\u001b[0m\n",
      "\u001b[32m2023-11-12 11:38:53.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-12 11:38:53.767930 batch 701 loss 13.458826111629605\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)\n",
    "optimizer = Adam(model.parameters())\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    train_epoch(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b98d626-8587-47f6-82c3-45420c4ee825",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57d0b248-2d46-431d-bd19-e5e37c49e3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = pd.concat([train_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "357979aa-14f1-45ef-a8e7-5b691d0948d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49734</td>\n",
       "      <td>5,6,9,26,32,55,96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67845</td>\n",
       "      <td>6,9,28,39,145,155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25302</td>\n",
       "      <td>0,6,28,40,116,168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57796</td>\n",
       "      <td>28,186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13676</td>\n",
       "      <td>6,23,177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track               tags\n",
       "0  49734  5,6,9,26,32,55,96\n",
       "1  67845  6,9,28,39,145,155\n",
       "2  25302  0,6,28,40,116,168\n",
       "3  57796             28,186\n",
       "4  13676           6,23,177"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81ee2836-084c-40d8-97d4-b804703b9215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76714, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c164d19-4bcf-4520-99f2-4156a99249b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataset = LSTMDataset(inference_df, track_id_to_embeddings, TAGS_N, True)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ba33916-b671-4a1c-850b-d914bda0784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_track_ids, inference_predictions, inference_cell_states = predict(model, inference_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "286d2473-6ba3-4a2e-a12b-839dec186954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76714, 76714, 76714)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inference_track_ids), len(inference_predictions), len(inference_cell_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee0c33-6768-42e2-9dd6-b5fa414e80d8",
   "metadata": {},
   "source": [
    "### Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "866a4fbb-db43-4de1-8816-6f8466107d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame([\n",
    "    {'track': track, 'prediction': ','.join([str(p) for p in probs])}\n",
    "    for track, probs in \n",
    "    zip(inference_track_ids, inference_predictions)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a488beb0-866b-4904-9879-5339e914eff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49734</td>\n",
       "      <td>3.8992786,3.7550733,4.485249,3.7612824,1.31616...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67845</td>\n",
       "      <td>3.9249747,2.7431135,3.5394266,3.8076763,0.7991...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25302</td>\n",
       "      <td>3.7137194,3.2424319,3.0893915,3.0597296,1.3846...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57796</td>\n",
       "      <td>5.4363995,1.5872772,4.2686834,5.607044,1.63424...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13676</td>\n",
       "      <td>3.5169446,2.976041,3.4261286,2.5848532,0.59583...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track                                         prediction\n",
       "0  49734  3.8992786,3.7550733,4.485249,3.7612824,1.31616...\n",
       "1  67845  3.9249747,2.7431135,3.5394266,3.8076763,0.7991...\n",
       "2  25302  3.7137194,3.2424319,3.0893915,3.0597296,1.3846...\n",
       "3  57796  5.4363995,1.5872772,4.2686834,5.607044,1.63424...\n",
       "4  13676  3.5169446,2.976041,3.4261286,2.5848532,0.59583..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63664050-d8a8-495d-ae4f-a71837b6e829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76714, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3946447-88a1-44f6-b052-35288c612461",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv('prediction_lstm_vae_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79d6b66-df8c-492c-adae-b91e016c4970",
   "metadata": {},
   "source": [
    "### Save embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb1477e2-4315-4743-93f7-67bce476959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id_to_lstm_embedding = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0e97b1a-c4d1-4378-a550-0488d842e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(VAE_LSTM_EMBEDDINGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f55e5fb-eea1-4a39-93de-f3c055e3e6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f9b599daa34b6f9770f21cb2c78096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ti, embeddings in tqdm(zip(inference_track_ids, inference_cell_states)):\n",
    "    fn = f\"{ti}.npy\"\n",
    "    fp = f\"{VAE_LSTM_EMBEDDINGS_DIR}/{fn}\"\n",
    "    np.save(fp, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734b750-180d-4cba-8e6e-1915e0e9aea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
