{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c2db941a-2b87-4a05-b325-c4a72fb7b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Any, Mapping, List, Tuple, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from loguru import logger\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.init import constant_, kaiming_normal_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn.utils.rnn import pack_sequence, unpack_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38609988-6e1b-4d98-a0db-356a34bfd81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/Users/artemvopilov/Programming/yandex_cup_2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd9a94d-fbff-4211-8b4f-015684ad331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = f\"{BASE_DIR}/data\"\n",
    "\n",
    "TRAIN_DF_PATH = f\"{DATA_DIR}/train.csv\"\n",
    "TEST_DF_PATH = f\"{DATA_DIR}/test.csv\"\n",
    "\n",
    "NORMED_EMBEDDINGS_DIR = f\"{BASE_DIR}/normed_embeddings\"\n",
    "PCA_EMBEDDINGS_DIR = f\"{BASE_DIR}/pca_embeddings\"\n",
    "VAE_EMBEDDINGS_DIR = f\"{BASE_DIR}/vae_embeddings\"\n",
    "NORMED_LSTM_EMBEDDINGS_DIR = f\"{BASE_DIR}/normed_lstm_embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2858b17-a1e6-400b-b9d4-95d71b1ec0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cpu\"\n",
    "\n",
    "TAGS_N = 256\n",
    "\n",
    "INPUT_DIM = 768\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = TAGS_N\n",
    "\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e8262d-2e63-4fa2-83f3-e90eedbf611d",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4828974f-1341-42c2-a788-a4077853d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_DF_PATH)\n",
    "test_df = pd.read_csv(TEST_DF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65311050-ae7f-455b-9c19-56872c707cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef067274c3843bfb9f75320563d7137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "track_id_to_embeddings = {}\n",
    "for fn in tqdm(os.listdir(NORMED_EMBEDDINGS_DIR)):\n",
    "    fp = f\"{NORMED_EMBEDDINGS_DIR}/{fn}\"\n",
    "\n",
    "    track_id = fn.split('.')[0]\n",
    "    embeddings = np.load(fp).astype(np.float32)\n",
    "    track_id_to_embeddings[track_id] = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8def69a2-f7b9-40b2-8a47-e56d171ff179",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "869d3554-064f-4128-bbf6-dc4150fdda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, track_id_to_embeddings: Dict[str, np.ndarray[np.float64]], tags_n: int, is_testing=False):\n",
    "        self._df = df\n",
    "        self._track_id_to_embeddings = track_id_to_embeddings\n",
    "        self._tags_n = tags_n\n",
    "        self._is_testing = is_testing\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[str, np.ndarray[np.float64], List[np.ndarray[np.int64]]]:\n",
    "        row = self._df.iloc[index]\n",
    "        track_id = row[\"track\"]\n",
    "        embeddings = self._track_id_to_embeddings[str(track_id)]\n",
    "        if self._is_testing:\n",
    "            return track_id, embeddings, np.array([])\n",
    "        tags = [int(x) for x in row[\"tags\"].split(',')]\n",
    "        target = np.zeros(self._tags_n)\n",
    "        target[tags] = 1\n",
    "        return track_id, embeddings, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a19ff4e5-46ea-4a25-99dc-0bf09492af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(b):\n",
    "    track_ids = torch.from_numpy(np.vstack([x[0] for x in b]))\n",
    "    embeddings = [torch.from_numpy(x[1]) for x in b]\n",
    "    targets = torch.from_numpy(np.vstack([x[2] for x in b]))\n",
    "    return track_ids, embeddings, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebe2258-1b70-4fad-8998-de418c3e3dae",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e6d37416-0c70-4689-aaa9-25bf856b6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.apply(self._init_layer)\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        embeddings = pack_sequence(embeddings, enforce_sorted=False)\n",
    "        cell_states, (final_hidden_state, final_cell_state) = self.lstm(embeddings)\n",
    "        first_layer_hidden_state = final_hidden_state[0, :, :]\n",
    "        return self.fc(first_layer_hidden_state), unpack_sequence(cell_states)\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.apply(self._init_layer)\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_layer(layer: nn.Module) -> None:\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            kaiming_normal_(layer.weight.data)\n",
    "            if layer.bias is not None:\n",
    "                constant_(layer.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664cc074-cacf-465d-89ea-17efab1f1ed9",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "06bf6112-8da7-4711-bdcb-f0ffbd4246f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = None\n",
    "    alpha = 0.8\n",
    "    for iteration, data in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        _, embeddings, target = data\n",
    "        \n",
    "        embeddings = [x.to(DEVICE) for x in embeddings]\n",
    "        target = target.to(DEVICE)\n",
    "        \n",
    "        predictions, _ = model(embeddings)\n",
    "        \n",
    "        loss = criterion(predictions, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if running_loss is None:\n",
    "            running_loss = loss.item()\n",
    "        else:\n",
    "            running_loss = alpha * loss.item() + (1 - alpha) * loss.item()\n",
    "        if iteration % 100 == 0:\n",
    "            logger.info(\"{} batch {} loss {}\".format(datetime.now(), iteration + 1, running_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584367b0-bc2d-4144-8d25-e59f752e49fd",
   "metadata": {},
   "source": [
    "### Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8655338e-d0a1-432b-90c7-c7427bade20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    track_ids = []\n",
    "    predictions = []\n",
    "    cell_states = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            track_id, embeddings, _ = data\n",
    "            \n",
    "            embeddings =  [x.to(DEVICE) for x in embeddings]\n",
    "            \n",
    "            batch_predictions, batch_cell_states = model(embeddings)\n",
    "\n",
    "            track_ids.append(track_id.numpy())\n",
    "            predictions.append(batch_predictions.detach().cpu().numpy())\n",
    "            cell_states.append([cs.detach().cpu().numpy() for cs in batch_cell_states])\n",
    "    track_ids = np.vstack(track_ids).ravel()\n",
    "    predictions = np.vstack(predictions)\n",
    "    cell_states = list(chain.from_iterable(cell_states))\n",
    "    return track_ids, predictions, cell_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a5a141-ea98-4753-8632-43b130031501",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e11ee9e2-aa1a-46fa-95bf-09c40bc7a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LSTMDataset(train_df, track_id_to_embeddings, TAGS_N, False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c438e2-e1fe-42e9-a39f-7378cb9da57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3824be971d429c833eaf8d9eda864e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-10 00:45:37.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-10 00:45:37.072460 batch 1 loss 24.6972738802433\u001b[0m\n",
      "\u001b[32m2023-11-10 00:47:19.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-10 00:47:19.991564 batch 101 loss 19.912205085158348\u001b[0m\n",
      "\u001b[32m2023-11-10 00:49:04.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-10 00:49:04.949913 batch 201 loss 16.165155679918826\u001b[0m\n",
      "\u001b[32m2023-11-10 00:50:50.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-10 00:50:50.134544 batch 301 loss 13.82649103924632\u001b[0m\n",
      "\u001b[32m2023-11-10 00:52:33.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-10 00:52:33.497937 batch 401 loss 16.763167725875974\u001b[0m\n",
      "\u001b[32m2023-11-10 00:54:22.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-10 00:54:22.987230 batch 501 loss 17.009682780131698\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)\n",
    "optimizer = Adam(model.parameters())\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    train_epoch(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b98d626-8587-47f6-82c3-45420c4ee825",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d0b248-2d46-431d-bd19-e5e37c49e3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = pd.concat([train_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357979aa-14f1-45ef-a8e7-5b691d0948d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee2836-084c-40d8-97d4-b804703b9215",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c164d19-4bcf-4520-99f2-4156a99249b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataset = LSTMDataset(inference_df, track_id_to_embeddings, TAGS_N, True)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba33916-b671-4a1c-850b-d914bda0784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_track_ids, inference_predictions, inference_cell_states = predict(model, inference_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286d2473-6ba3-4a2e-a12b-839dec186954",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inference_track_ids), len(inference_predictions), len(inference_cell_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee0c33-6768-42e2-9dd6-b5fa414e80d8",
   "metadata": {},
   "source": [
    "### Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a4fbb-db43-4de1-8816-6f8466107d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame([\n",
    "    {'track': track, 'prediction': ','.join([str(p) for p in probs])}\n",
    "    for track, probs in \n",
    "    zip(inference_track_ids, inference_predictions)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a488beb0-866b-4904-9879-5339e914eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63664050-d8a8-495d-ae4f-a71837b6e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3946447-88a1-44f6-b052-35288c612461",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv('prediction_lstm_normed_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79d6b66-df8c-492c-adae-b91e016c4970",
   "metadata": {},
   "source": [
    "### Save embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1477e2-4315-4743-93f7-67bce476959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id_to_lstm_embedding = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e97b1a-c4d1-4378-a550-0488d842e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(LSTM_EMBEDDINGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f55e5fb-eea1-4a39-93de-f3c055e3e6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ti, embeddings in tqdm(track_id_to_pca_embeddings.items()):\n",
    "    fn = f\"{ti}.npy\"\n",
    "    fp = f\"{NORMED_LSTM_EMBEDDINGS_DIR}/{fn}\"\n",
    "    np.save(fp, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734b750-180d-4cba-8e6e-1915e0e9aea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
