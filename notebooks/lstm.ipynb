{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c2db941a-2b87-4a05-b325-c4a72fb7b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Any, Mapping, List, Tuple, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from loguru import logger\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.init import constant_, kaiming_normal_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "38609988-6e1b-4d98-a0db-356a34bfd81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/Users/artemvopilov/Programming/yandex_cup_2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7fd9a94d-fbff-4211-8b4f-015684ad331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = f\"{BASE_DIR}/data\"\n",
    "\n",
    "TRAIN_DF_PATH = f\"{DATA_DIR}/train.csv\"\n",
    "TEST_DF_PATH = f\"{DATA_DIR}/test.csv\"\n",
    "\n",
    "NORMED_EMBEDDINGS_DIR = f\"{BASE_DIR}/normed_embeddings\"\n",
    "PCA_EMBEDDINGS_DIR = f\"{BASE_DIR}/pca_embeddings\"\n",
    "VAE_EMBEDDINGS_DIR = f\"{BASE_DIR}/vae_embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f2858b17-a1e6-400b-b9d4-95d71b1ec0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cpu\"\n",
    "\n",
    "TAGS_N = 256\n",
    "\n",
    "INPUT_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = TAGS_N\n",
    "\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e8262d-2e63-4fa2-83f3-e90eedbf611d",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4828974f-1341-42c2-a788-a4077853d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_DF_PATH)\n",
    "test_df = pd.read_csv(TEST_DF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "65311050-ae7f-455b-9c19-56872c707cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976bd7cc6bb541669ee91cc1dba6701b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "track_id_to_embeddings = {}\n",
    "for fn in tqdm(os.listdir(VAE_EMBEDDINGS_DIR)):\n",
    "    fp = f\"{VAE_EMBEDDINGS_DIR}/{fn}\"\n",
    "\n",
    "    track_id = fn.split('.')[0]\n",
    "    embeddings = np.load(fp).astype(np.float32)\n",
    "    track_id_to_embeddings[track_id] = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8def69a2-f7b9-40b2-8a47-e56d171ff179",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "869d3554-064f-4128-bbf6-dc4150fdda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, track_id_to_embeddings: Dict[str, np.ndarray[np.float64]], tags_n: int, is_testing=False):\n",
    "        self._df = df\n",
    "        self._track_id_to_embeddings = track_id_to_embeddings\n",
    "        self._tags_n = tags_n\n",
    "        self._is_testing = is_testing\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[str, np.ndarray[np.float64], List[np.ndarray[np.int64]]]:\n",
    "        row = self._df.iloc[index]\n",
    "        track_id = row[\"track\"]\n",
    "        embeddings = self._track_id_to_embeddings[str(track_id)]\n",
    "        if self._is_testing:\n",
    "            return track_id, embeddings, np.array([])\n",
    "        tags = [int(x) for x in row[\"tags\"].split(',')]\n",
    "        target = np.zeros(self._tags_n)\n",
    "        target[tags] = 1\n",
    "        return track_id, embeddings, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a19ff4e5-46ea-4a25-99dc-0bf09492af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(b):\n",
    "    track_ids = torch.from_numpy(np.vstack([x[0] for x in b]))\n",
    "    embeddings = [torch.from_numpy(x[1]) for x in b]\n",
    "    targets = torch.from_numpy(np.vstack([x[2] for x in b]))\n",
    "    return track_ids, embeddings, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebe2258-1b70-4fad-8998-de418c3e3dae",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e6d37416-0c70-4689-aaa9-25bf856b6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.apply(self._init_layer)\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        rnn_outputs, (hn, cn) = self.rnn(embeddings)\n",
    "        return self.fc(hn[0, :, :])\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.apply(self._init_layer)\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_layer(layer: nn.Module) -> None:\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            kaiming_normal_(layer.weight.data)\n",
    "            if layer.bias is not None:\n",
    "                constant_(layer.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664cc074-cacf-465d-89ea-17efab1f1ed9",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "06bf6112-8da7-4711-bdcb-f0ffbd4246f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = None\n",
    "    alpha = 0.8\n",
    "    for iteration, data in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        _, embeddings, target = data\n",
    "        \n",
    "        embeddings = pad_sequence([x.to(DEVICE) for x in embeddings], batch_first=True)\n",
    "        target = target.to(DEVICE)\n",
    "        \n",
    "        model_outputs = model(embeddings)\n",
    "        \n",
    "        loss = criterion(model_outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if running_loss is None:\n",
    "            running_loss = loss.item()\n",
    "        else:\n",
    "            running_loss = alpha * loss.item() + (1 - alpha) * loss.item()\n",
    "        if iteration % 100 == 0:\n",
    "            logger.info(\"{} batch {} loss {}\".format(datetime.now(), iteration + 1, running_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584367b0-bc2d-4144-8d25-e59f752e49fd",
   "metadata": {},
   "source": [
    "### Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8655338e-d0a1-432b-90c7-c7427bade20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    track_ids = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            track_id, embeddings, _ = data\n",
    "            \n",
    "            embeddings =  pad_sequence([x.to(DEVICE) for x in embeddings], batch_first=True)\n",
    "            \n",
    "            model_outputs = model(embeddings)\n",
    "\n",
    "            track_ids.append(track_id.numpy())\n",
    "            predictions.append(model_outputs.detach().cpu().numpy())\n",
    "    predictions = np.vstack(predictions)\n",
    "    track_ids = np.vstack(track_ids).ravel()\n",
    "    return track_ids, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a5a141-ea98-4753-8632-43b130031501",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e11ee9e2-aa1a-46fa-95bf-09c40bc7a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LSTMDataset(train_df, track_id_to_embeddings, TAGS_N, False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c438e2-e1fe-42e9-a39f-7378cb9da57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e3e2663d804010b5ce0040aae4335e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-06 20:11:29.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:11:29.418800 batch 1 loss 20.898002065718174\u001b[0m\n",
      "\u001b[32m2023-11-06 20:11:40.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:11:40.061096 batch 101 loss 19.238709829747677\u001b[0m\n",
      "\u001b[32m2023-11-06 20:11:49.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:11:49.440857 batch 201 loss 17.855387296527624\u001b[0m\n",
      "\u001b[32m2023-11-06 20:12:01.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:12:01.276574 batch 301 loss 16.847806312143803\u001b[0m\n",
      "\u001b[32m2023-11-06 20:12:10.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:12:10.337045 batch 401 loss 19.947432152926922\u001b[0m\n",
      "\u001b[32m2023-11-06 20:12:19.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:12:19.272106 batch 501 loss 19.00167796947062\u001b[0m\n",
      "\u001b[32m2023-11-06 20:12:26.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:12:26.995460 batch 601 loss 17.699312414973974\u001b[0m\n",
      "\u001b[32m2023-11-06 20:12:35.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:12:35.213973 batch 701 loss 17.819254215806723\u001b[0m\n",
      "\u001b[32m2023-11-06 20:12:44.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:12:44.519797 batch 1 loss 18.436677681282163\u001b[0m\n",
      "\u001b[32m2023-11-06 20:12:55.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:12:55.004841 batch 101 loss 21.12359170615673\u001b[0m\n",
      "\u001b[32m2023-11-06 20:13:07.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:13:07.159385 batch 201 loss 16.855951204895973\u001b[0m\n",
      "\u001b[32m2023-11-06 20:13:16.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:13:16.832761 batch 301 loss 19.24385218322277\u001b[0m\n",
      "\u001b[32m2023-11-06 20:13:26.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:13:26.924420 batch 401 loss 19.817895460873842\u001b[0m\n",
      "\u001b[32m2023-11-06 20:13:37.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:13:37.719198 batch 501 loss 19.401729619130492\u001b[0m\n",
      "\u001b[32m2023-11-06 20:13:46.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:13:46.790134 batch 601 loss 18.57412789389491\u001b[0m\n",
      "\u001b[32m2023-11-06 20:13:55.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:13:55.337363 batch 701 loss 17.477862242609262\u001b[0m\n",
      "\u001b[32m2023-11-06 20:14:02.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:14:02.976834 batch 1 loss 18.766257109120488\u001b[0m\n",
      "\u001b[32m2023-11-06 20:14:10.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:14:10.545654 batch 101 loss 19.84783790819347\u001b[0m\n",
      "\u001b[32m2023-11-06 20:14:19.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:14:19.009165 batch 201 loss 19.287959415465593\u001b[0m\n",
      "\u001b[32m2023-11-06 20:14:27.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:14:27.236863 batch 301 loss 15.911395236849785\u001b[0m\n",
      "\u001b[32m2023-11-06 20:14:35.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_epoch\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m2023-11-06 20:14:35.971073 batch 401 loss 16.408352894708514\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)\n",
    "optimizer = Adam(model.parameters())\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    train_epoch(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b98d626-8587-47f6-82c3-45420c4ee825",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0495db-90b0-4083-a161-dab5fe68d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = LSTMDataset(test_df, track_id_to_embeddings, TAGS_N, True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767bad71-72a1-41f5-ab83-f1765a5622f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inference_dataset = LSTMDataset(train_df, track_id_to_embeddings, TAGS_N, False)\n",
    "train_inference_loader = DataLoader(train_inference_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b186b-817f-4198-8304-c0d839919715",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_track_ids, test_predictions = predict(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5dd38f-9637-43b8-9241-5f5ba8f5da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inference_track_ids, train_inference_predictions = predict(model, train_inference_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f026f0a-f331-484d-91b5-0631f737f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(test_track_ids) + list(train_inference_track_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107d40a6-d852-45a4-8bfb-b7636930081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(test_predictions) + list(train_inference_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87584aa4-16e9-4b00-9ebe-90101cd17f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame([\n",
    "    {'track': track, 'prediction': ','.join([str(p) for p in probs])}\n",
    "    for track, probs in \n",
    "    zip(list(test_track_ids) + list(train_inference_track_ids), list(test_predictions) + list(train_inference_predictions))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ddbd1-135f-49af-913f-f5badba6cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6d8e82-dc37-476a-8155-9c114de70db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c928d0-8cea-4122-9c34-59c1850261fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv('prediction_lstm_vae.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734b750-180d-4cba-8e6e-1915e0e9aea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
