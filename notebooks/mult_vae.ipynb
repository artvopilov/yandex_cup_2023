{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52f8160c-d2ad-4073-bb5f-944b286ed2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Any, Mapping, List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from loguru import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.init import constant_, kaiming_normal_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from catalyst import dl, metrics\n",
    "from catalyst.engines import Engine, CPUEngine, GPUEngine, DataParallelEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d59c9979-195a-4f73-9ff5-9df666861daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_engine() -> \"Engine\":\n",
    "    if not torch.cuda.is_available():\n",
    "        return CPUEngine()\n",
    "    return GPUEngine() if torch.cuda.device_count() == 1 else DataParallelEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21df2750-2daf-4dbd-bc8a-8b696f916a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiVaeModel(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, latent_dim: int, dropout: float = 0.2) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.encoder_dims = [self.input_dim, self.hidden_dim, self.latent_dim * 2]\n",
    "        self.decoder_dims = [self.latent_dim, self.hidden_dim, self.input_dim]\n",
    "\n",
    "        self.encoder = self._build_layers(self.encoder_dims)\n",
    "        self.decoder = self._build_layers(self.decoder_dims)\n",
    "\n",
    "        self.apply(self._init_layer)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        h = nn.functional.dropout(x, self.dropout, training=self.training)\n",
    "        h = self.encoder(h)\n",
    "\n",
    "        mu = h[:, :self.latent_dim]\n",
    "        log_var = h[:, self.latent_dim:]\n",
    "\n",
    "        z = self._reparameterize(mu, log_var)\n",
    "        z = self.decoder(z)\n",
    "        return z, mu, log_var\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.apply(self._init_layer)\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_layers(dims: List[int]) -> nn.Sequential:\n",
    "        layers = []\n",
    "        for i in range(len(dims) - 1):\n",
    "            layers.append(nn.Linear(dims[i], dims[i + 1]))\n",
    "            if i + 1 < len(dims) - 1:\n",
    "                layers.append(nn.BatchNorm1d(dims[i + 1]))\n",
    "                layers.append(nn.ReLU())\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_layer(layer: nn.Module) -> None:\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            kaiming_normal_(layer.weight.data)\n",
    "            if layer.bias is not None:\n",
    "                constant_(layer.bias.data, 0)\n",
    "\n",
    "    def _reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f89676d-a0db-4452-8604-4220a24d9fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiVaeDataset(Dataset):\n",
    "    _embedding_ids: List[int]\n",
    "    _embedding_id_to_embedding: Dict[int, np.ndarray[np.float64]]\n",
    "\n",
    "    def __init__(self, embedding_ids: List[int], embedding_id_to_embedding: Dict[int, np.ndarray[np.float64]]) -> None:\n",
    "        super(Dataset).__init__()\n",
    "        self._embedding_ids = embedding_ids\n",
    "        self._embedding_id_to_embedding = embedding_id_to_embedding\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._embedding_ids)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Mapping[str, Any]:\n",
    "        embedding_id = self._embedding_ids[index]\n",
    "        embedding = self._embedding_id_to_embedding[embedding_id]\n",
    "        return {\"embedding_id\": embedding_id, \"embedding\": embedding}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af66c65b-f9eb-4abc-b1cd-5c697113ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiVaeRunner(dl.Runner):\n",
    "    _loader_additive_metrics: Dict[str, metrics.AdditiveMetric]\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MultiVaeRunner, self).__init__()\n",
    "\n",
    "    @property\n",
    "    def logger(self) -> Any:\n",
    "        pass\n",
    "\n",
    "    def on_loader_start(self, runner: dl.Runner) -> None:\n",
    "        super().on_loader_start(runner)\n",
    "        self._loader_additive_metrics = {\n",
    "            metric_name: metrics.AdditiveMetric(compute_on_call=False)\n",
    "            for metric_name in [\"loss_ae\", \"loss_kld\", \"loss\"]}\n",
    "\n",
    "    def handle_batch(self, batch: Mapping[str, Any]) -> None:\n",
    "        x = batch[\"embedding\"]\n",
    "        z, mu, log_var = self.model(x)\n",
    "\n",
    "        anneal = min(self.hparams[\"anneal_cap\"], self.batch_step / self.hparams[\"anneal_total_steps\"])\n",
    "\n",
    "        loss_ae = self._compute_loss_ae(x, z)\n",
    "        loss_kld = self._compute_loss_kld(mu, log_var)\n",
    "        loss = loss_ae + anneal * loss_kld\n",
    "\n",
    "        self.batch_metrics = {\"loss_ae\": loss_ae, \"loss_kld\": loss_kld, \"loss\": loss}\n",
    "        for metric_name, metric in self.batch_metrics.items():\n",
    "            self._loader_additive_metrics[metric_name].update(metric.item(), self.batch_size)\n",
    "\n",
    "    def on_loader_end(self, runner: dl.Runner) -> None:\n",
    "        for metric_name, metric in self._loader_additive_metrics.items():\n",
    "            self.loader_metrics[metric_name] = metric.compute()[0]\n",
    "        super().on_loader_end(runner)\n",
    "\n",
    "    def predict_batch(self, batch: Mapping[str, Any], **kwargs) -> Mapping[str, Any]:\n",
    "        x = batch[\"embedding\"]\n",
    "        z, mu, log_var = self.model(x)\n",
    "        return {**batch, \"output\": mu}\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_loss_ae(x: torch.Tensor, z: torch.Tensor) -> float:\n",
    "        return -torch.mean(torch.sum(nn.functional.log_softmax(z, dim=1) * x, dim=1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_loss_kld(mu: torch.Tensor, log_var: torch.Tensor) -> float:\n",
    "        return -0.5 * torch.mean(torch.sum(1 + log_var - mu.pow(2) - log_var.exp(), dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc345243-db62-4a18-ba1d-fcaf86961cb5",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05a42968-77c7-4bae-a219-e684e165bcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/Users/artemvopilov/Programming/yandex_cup_2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49d20488-dab2-46e9-8ac9-3a540bc19cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMED_EMBEDDINGS_DIR = f\"{BASE_DIR}/normed_embeddings\"\n",
    "VAE_EMBEDDINGS_DIR = f\"{BASE_DIR}/vae_embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f84cbde2-44cb-4e09-9a92-2fbb7c2d1724",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 768\n",
    "HIDDEN_DIM = 256\n",
    "LATENT_DIM = 64\n",
    "\n",
    "TRAIN_BATCH_SIZE = 256\n",
    "VALID_BATCH_SIZE = 2048\n",
    "INFERENCE_BATCH_SIZE = 8192\n",
    "\n",
    "LR_SCHEDULER_STEP = 5\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "ANNEAL_CAP = 0.5\n",
    "ANNEAL_TOTAL_STEPS = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d86f48-f332-4760-aa91-9df8735dc3c6",
   "metadata": {},
   "source": [
    "### Read embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6d4cd59-274d-4df1-9971-cd0a5cd03dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5770b014324b21b7499fbdaeeb64dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "track_id_to_embeddings = {}\n",
    "for fn in tqdm(os.listdir(NORMED_EMBEDDINGS_DIR)):\n",
    "    fp = f\"{NORMED_EMBEDDINGS_DIR}/{fn}\"\n",
    "\n",
    "    track_id = fn.split('.')[0]\n",
    "    embeddings = np.load(fp)\n",
    "    track_id_to_embeddings[track_id] = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1d6219-2b01-46ce-9c4d-6bfcb53976d3",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38ff0ea6-49a6-4a9e-b9eb-0da2546121ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29fab9f038dd4b50bc4746384bf3b845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_id_to_track_id_pos = {}\n",
    "embedding_ids = []\n",
    "embedding_id_to_embedding = {}\n",
    "for ti, embeds in tqdm(track_id_to_embeddings.items()):\n",
    "    for ei, embed in enumerate(embeds):\n",
    "        embedding_id = len(embedding_id_to_track_id_pos)\n",
    "\n",
    "        embedding_id_to_track_id_pos[embedding_id] = (ti, ei)\n",
    "        embedding_ids.append(embedding_id)\n",
    "        embedding_id_to_embedding[embedding_id] = embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "868364c1-b57b-44c0-aaa1-eb8de566d230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4452609, 4452609, 4452609)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_id_to_track_id_pos), len(embedding_ids), len(embedding_id_to_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4077256c-1593-41e4-9a9e-d370223da6cb",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd7c3f7c-beb2-473d-a1c5-af7f23eaa02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-06 17:31:01.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mDivided df into train 800000 and validation 200000\u001b[0m\n",
      "\u001b[32m2023-11-06 17:31:01.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mDatasets created\u001b[0m\n",
      "\u001b[32m2023-11-06 17:31:01.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mLoaders created\u001b[0m\n",
      "\u001b[32m2023-11-06 17:31:01.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m14\u001b[0m - \u001b[1mModel initialized with config\u001b[0m\n",
      "\u001b[32m2023-11-06 17:31:01.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mOptimizer initialized\u001b[0m\n",
      "\u001b[32m2023-11-06 17:31:01.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mScheduler initialized\u001b[0m\n",
      "\u001b[32m2023-11-06 17:31:01.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mUsing engine <catalyst.engines.torch.CPUEngine object at 0x137242230>\u001b[0m\n",
      "\u001b[32m2023-11-06 17:31:01.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mCallbacks created: [<catalyst.callbacks.backward.BackwardCallback object at 0x137241690>, <catalyst.callbacks.optimizer.OptimizerCallback object at 0x13724a260>, <catalyst.callbacks.scheduler.SchedulerCallback object at 0x13724bd90>, <catalyst.callbacks.misc.EarlyStoppingCallback object at 0x137248e80>]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0899f9cc516c431b9cf1c33a3ec34050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1/10 * Epoch (train):   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (1/10) loss: -50960.788538240995 | loss_ae: -50968.26594083464 | loss_kld: 126.1702626770017 | lr: 0.001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3ab79b4b534c4587ffc788fb4e040f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1/10 * Epoch (valid):   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (1/10) loss: -143223.86907499997 | loss_ae: -143234.138545 | loss_kld: 64.70226213867187 | lr: 0.001 | momentum: 0.9\n",
      "* Epoch (1/10) lr: 0.001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ebfd5274a84ef6b7df4ccd62bbe34a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2/10 * Epoch (train):   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (2/10) loss: -288744.03524749953 | loss_ae: -288757.1866500001 | loss_kld: 55.754120119628936 | lr: 0.001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c6db2d7dd043a0a0a75b6485d73232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2/10 * Epoch (valid):   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (2/10) loss: -459650.98819000006 | loss_ae: -459668.17545000016 | loss_kld: 53.73457075073241 | lr: 0.001 | momentum: 0.9\n",
      "* Epoch (2/10) lr: 0.001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1bebccbaaf466989f7e81165fc0838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3/10 * Epoch (train):   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (3/10) loss: -684926.9470799983 | loss_ae: -684951.6161200005 | loss_kld: 61.1147610839844 | lr: 0.001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92237b9947942e0bc149e94eaa67c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3/10 * Epoch (valid):   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (3/10) loss: -914947.0939399999 | loss_ae: -914989.1469800003 | loss_kld: 87.42091524414064 | lr: 0.001 | momentum: 0.9\n",
      "* Epoch (3/10) lr: 0.001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1470213e386e4a4d8133df4249779bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "4/10 * Epoch (train):   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (4/10) loss: -1223736.6033799993 | loss_ae: -1223777.476380002 | loss_kld: 81.86823143066422 | lr: 0.001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cbf130b40874f64a02cf4f2ce9aa585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "4/10 * Epoch (valid):   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (4/10) loss: -1549430.0152400003 | loss_ae: -1549470.0472000001 | loss_kld: 80.07871560546876 | lr: 0.001 | momentum: 0.9\n",
      "* Epoch (4/10) lr: 0.001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6beb878989d743c48fcf85ae1b207c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5/10 * Epoch (train):   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (5/10) loss: -1949670.0936400013 | loss_ae: -1949729.2105200004 | loss_kld: 118.23254907714833 | lr: 0.001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93c25ec97c04a1ebf3991b7fc9a3869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5/10 * Epoch (valid):   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (5/10) loss: -2482695.2803999996 | loss_ae: -2482753.2991199996 | loss_kld: 116.01313360595704 | lr: 0.001 | momentum: 0.9\n",
      "* Epoch (5/10) lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb487e363484affa0f4d8500843937a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "6/10 * Epoch (train):   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (6/10) loss: -2385286.6455200007 | loss_ae: -2385331.21748 | loss_kld: 89.1446086157226 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efdfbea54cf421e885b477eb1796453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "6/10 * Epoch (valid):   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (6/10) loss: -2440712.9044 | loss_ae: -2440750.107440001 | loss_kld: 74.40477052734374 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (6/10) lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627267c364b84651bd26a87d55bed27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "7/10 * Epoch (train):   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (7/10) loss: -2465186.4771200023 | loss_ae: -2465221.404239993 | loss_kld: 69.85346609252946 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db86397857ac4888b58c7a0ce95488f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "7/10 * Epoch (valid):   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (7/10) loss: -2522021.5968 | loss_ae: -2522054.4688 | loss_kld: 65.73312286376955 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (7/10) lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9217eecbaf94487392d46c03cb9d09df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "8/10 * Epoch (train):   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (8/10) loss: -2546054.129360002 | loss_ae: -2546085.914800003 | loss_kld: 63.5701711865236 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9178c8369d84680b564e77a95d6effb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "8/10 * Epoch (valid):   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (8/10) loss: -2602613.8075999995 | loss_ae: -2602644.051600001 | loss_kld: 60.48229815673829 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (8/10) lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f45424d22234f99aa566b67480c3835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "9/10 * Epoch (train):   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (9/10) loss: -2628227.0280000055 | loss_ae: -2628256.609840008 | loss_kld: 59.163841883544855 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6266e1c4776d420eaecb8d3a15a2ad37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "9/10 * Epoch (valid):   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (9/10) loss: -2685532.2866399996 | loss_ae: -2685560.674 | loss_kld: 56.801065078125006 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (9/10) lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64197ae6d97d4b3b82336c5df946591f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "10/10 * Epoch (train):   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (10/10) loss: -2711708.5190400044 | loss_ae: -2711736.440799999 | loss_kld: 55.84546118652339 | lr: 0.0001 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd6e0c7a75a44b8b019eb12133fd293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "10/10 * Epoch (valid):   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (10/10) loss: -2771299.6408799994 | loss_ae: -2771326.361839999 | loss_kld: 53.44989376220705 | lr: 0.0001 | momentum: 0.9\n",
      "* Epoch (10/10) lr: 1e-05 | momentum: 0.9\n"
     ]
    }
   ],
   "source": [
    "train_embedding_ids, valid_embedding_ids = train_test_split(embedding_ids[:1000000], test_size=0.2)\n",
    "logger.info(f\"Divided df into train {len(train_embedding_ids)} and validation {len(valid_embedding_ids)}\")\n",
    "\n",
    "train_dataset = MultiVaeDataset(train_embedding_ids, embedding_id_to_embedding)\n",
    "valid_dataset = MultiVaeDataset(valid_embedding_ids, embedding_id_to_embedding)\n",
    "logger.info(\"Datasets created\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=VALID_BATCH_SIZE)\n",
    "loaders = OrderedDict([('train', train_loader), ('valid', valid_loader)])\n",
    "logger.info(\"Loaders created\")\n",
    "\n",
    "model = MultiVaeModel(input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM, latent_dim=LATENT_DIM, dropout=0.1)\n",
    "logger.info(\"Model initialized with config\")\n",
    "optimizer = Adam(params=model.parameters())\n",
    "logger.info(\"Optimizer initialized\")\n",
    "lr_scheduler = StepLR(optimizer=optimizer, step_size=LR_SCHEDULER_STEP)\n",
    "logger.info(\"Scheduler initialized\")\n",
    "\n",
    "num_epochs = EPOCHS\n",
    "\n",
    "hparams = {\"anneal_cap\": ANNEAL_CAP, \"anneal_total_steps\": ANNEAL_TOTAL_STEPS}\n",
    "\n",
    "engine = get_available_engine()\n",
    "logger.info(f\"Using engine {engine}\")\n",
    "\n",
    "callbacks = [\n",
    "    dl.BackwardCallback(metric_key=\"loss\"),\n",
    "    dl.OptimizerCallback(\"loss\", accumulation_steps=1),\n",
    "    dl.SchedulerCallback(),\n",
    "    dl.EarlyStoppingCallback(patience=2, loader_key=\"valid\", metric_key=\"loss\", minimize=True)]\n",
    "logger.info(f\"Callbacks created: {callbacks}\")\n",
    "\n",
    "runner = MultiVaeRunner()\n",
    "runner.train(\n",
    "    loaders=loaders,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=lr_scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    hparams=hparams,\n",
    "    engine=engine,\n",
    "    verbose=True,\n",
    "    timeit=False,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3509e8-f5b5-496d-857a-2055a23544b1",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57cbf830-fd2e-4146-a0fc-666825c7a3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-06 17:51:57.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mComputing embeddings by 544.0 batches of size 8192\u001b[0m\n",
      "\u001b[32m2023-11-06 17:52:03.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m5.15 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:52:09.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m10.29 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:52:14.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m15.44 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:52:21.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m20.59 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:52:26.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m25.74 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:52:32.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m30.88 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:52:38.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m36.03 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:52:44.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m41.18 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:52:51.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m46.32 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:52:56.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m51.47 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:53:02.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m56.62 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:53:07.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m61.76 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:53:13.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m66.91 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:53:18.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m72.06 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:53:24.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m77.21 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:53:30.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m82.35 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:53:35.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m87.5 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:53:43.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m92.65 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:53:52.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m97.79 % batches processed\u001b[0m\n",
      "\u001b[32m2023-11-06 17:53:54.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mComputed embeddings\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "inference_dataset = MultiVaeDataset(embedding_ids, embedding_id_to_embedding)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=INFERENCE_BATCH_SIZE)\n",
    "\n",
    "batches_n = np.ceil(len(inference_dataset) / INFERENCE_BATCH_SIZE)\n",
    "batches_5_perc = np.ceil(batches_n / 20)\n",
    "\n",
    "logger.info(f\"Computing embeddings by {batches_n} batches of size {INFERENCE_BATCH_SIZE}\")\n",
    "\n",
    "track_id_to_vae_embeddings = {ti: [None] * len(embeddings) for ti, embeddings in track_id_to_embeddings.items()}\n",
    "batch_i = 0\n",
    "for predictions in runner.predict_loader(loader=inference_loader, model=model, engine=engine):\n",
    "    batch_embedding_ids = predictions[\"embedding_id\"].detach().cpu().numpy()\n",
    "    batch_vae_embeddings = predictions[\"output\"].detach().cpu().numpy()\n",
    "\n",
    "    for ei, vae_embed in zip(batch_embedding_ids, batch_vae_embeddings):\n",
    "        ti, pos = embedding_id_to_track_id_pos[ei]\n",
    "        track_id_to_vae_embeddings[ti][pos] = vae_embed\n",
    "\n",
    "    batch_i += 1\n",
    "    if batch_i % batches_5_perc == 0:\n",
    "        logger.info(f'{round(100 * batch_i / batches_n, 2)} % batches processed')\n",
    "logger.info(\"Computed embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1996116e-d960-4672-9f43-2c371c1033aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76714"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(track_id_to_vae_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40da9d8-7b0f-4702-86d3-18b38806590b",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80443e31-21d2-4c77-991c-20f43c0a11c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(VAE_EMBEDDINGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a905ac2a-d0e9-45f1-839e-fd42b850bf22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1256d4d6b2c247d7b91408502168c956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ti, embeddings in tqdm(track_id_to_vae_embeddings.items()):\n",
    "    fn = f\"{ti}.npy\"\n",
    "    fp = f\"{VAE_EMBEDDINGS_DIR}/{fn}\"\n",
    "    np.save(fp, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a540643-6e1c-49a2-b9a8-0fa378df2ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
